{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kgana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textdistance\n",
    "import nltk\n",
    "import time\n",
    "from csv import writer\n",
    "from csv import reader\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInstructions to set up with pip\\npip install textdistance\\npip install nltk\\npip install csv\\npip install numpy\\nnumpy and random should be installed with python\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Instructions to set up with pip\n",
    "pip install textdistance\n",
    "pip install nltk\n",
    "pip install csv\n",
    "pip install numpy\n",
    "numpy and random should be installed with python\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Terrible version\\ndef doOperation(data, principal):       \\n    compared = []\\n    comparedVal = []\\n    \\n    #Checks to see what sentences have the same element_name and reg_name\\n    for comp in data:\\n        if principal[2] == comp[2] and principal[4] == comp[4]:\\n            compared.append(comp[1])\\n        \\n    print(len(compared))\\n    \\n    \\n    principal[1] = principal[1].replace(\"++++\", \" \")\\n    principal[1] = principal[1].replace(\" .\", \".\")\\n    principal[1] = principal[1].replace(\"  \", \" \")\\n    principal[1] = principal[1].replace(\" ,\", \",\")\\n            \\n    #goes through the entire compared list to the message of curr and conducts a syntactical similarity test\\n    for idx,item in enumerate(compared):\\n        item = item.replace(\"++++\", \" \")\\n        item = item.replace(\" .\", \".\")\\n        item = item.replace(\"  \", \" \")\\n        item = item.replace(\" ,\", \",\")\\n        tokens_1 = principal[1].split()\\n        tokens_2 = item.split()\\n        tokens_v2_1 = [word for word in tokens_1 if not word in stopwords.words()]\\n        tokens_v2_2 = [word for word in tokens_2 if not word in stopwords.words()]\\n        comparedVal.append(100 * textdistance.jaccard(tokens_v2_1 , tokens_v2_2))\\n\\n    finalVals = comparedVal\\n    compFinal = compared\\n    finalVals.sort(reverse = True)\\n\\n    final = []\\n    \\n    for i in range (len(compared)):\\n        found = False\\n        cnt = 0;\\n        while found == False:\\n            if comparedVal[cnt] == finalVals[i]:\\n                if compared[cnt] != \"empty\":\\n                    found = True\\n                    final.append(compared[cnt])\\n                    compared[cnt] = \"empty\"\\n            cnt = cnt + 1\\n\\n \\n    This script is for printing and readability. Remove once you want to start storing the data some other way\\n    \\n    print(\"Number: \" + str(principal[0]))\\n    print(\"Message: \" + str(principal[1]))\\n    print(\"\")\\n    print(len(final))\\n    print(len(finalVals))\\n    At this point you have finalVals and final in lists final has the sentences and finalVals has the scores and figure out how you\\n    you want to store the data\\n    \\n\\n    \\n    for i in range (11):\\n        None\\n\\n        add final[i] to the place to store\\n        add finalVals[i] to the place to store\\n\\ndef main():\\n    print(\"start\")\\n    principal = []\\n    data = []\\n    # open both files and add rows to the lists above. Compared will be used later\\n    t0 = time.perf_counter()\\n    with open(\\'data_filtered20.csv\\', encoding=\"utf8\") as csv:\\n        csv_reader = reader(csv)\\n        for row in csv_reader:\\n            data.append(row)\\n    print(\"data finished\")\\n    with open(\\'principal_filtered20.csv\\', encoding=\"utf8\") as csv:\\n        csv_reader = reader(csv)\\n        for row in csv_reader:\\n            principal.append(row)\\n    print(\"principal finished\")\\n    for index, row in enumerate(principal):\\n        if index is not 0:\\n            t2 = time.perf_counter()\\n            doOperation(data,row)\\n            print(str(index) + \" finished in \" + str(t2- t0) + \" seconds\")\\n    t1 = time.perf_counter()\\n    print(str(t1 - t0))  \\n    \\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Terrible version\n",
    "def doOperation(data, principal):       \n",
    "    compared = []\n",
    "    comparedVal = []\n",
    "    \n",
    "    #Checks to see what sentences have the same element_name and reg_name\n",
    "    for comp in data:\n",
    "        if principal[2] == comp[2] and principal[4] == comp[4]:\n",
    "            compared.append(comp[1])\n",
    "        \n",
    "    print(len(compared))\n",
    "    \n",
    "    \n",
    "    principal[1] = principal[1].replace(\"++++\", \" \")\n",
    "    principal[1] = principal[1].replace(\" .\", \".\")\n",
    "    principal[1] = principal[1].replace(\"  \", \" \")\n",
    "    principal[1] = principal[1].replace(\" ,\", \",\")\n",
    "            \n",
    "    #goes through the entire compared list to the message of curr and conducts a syntactical similarity test\n",
    "    for idx,item in enumerate(compared):\n",
    "        item = item.replace(\"++++\", \" \")\n",
    "        item = item.replace(\" .\", \".\")\n",
    "        item = item.replace(\"  \", \" \")\n",
    "        item = item.replace(\" ,\", \",\")\n",
    "        tokens_1 = principal[1].split()\n",
    "        tokens_2 = item.split()\n",
    "        tokens_v2_1 = [word for word in tokens_1 if not word in stopwords.words()]\n",
    "        tokens_v2_2 = [word for word in tokens_2 if not word in stopwords.words()]\n",
    "        comparedVal.append(100 * textdistance.jaccard(tokens_v2_1 , tokens_v2_2))\n",
    "\n",
    "    finalVals = comparedVal\n",
    "    compFinal = compared\n",
    "    finalVals.sort(reverse = True)\n",
    "\n",
    "    final = []\n",
    "    \n",
    "    for i in range (len(compared)):\n",
    "        found = False\n",
    "        cnt = 0;\n",
    "        while found == False:\n",
    "            if comparedVal[cnt] == finalVals[i]:\n",
    "                if compared[cnt] != \"empty\":\n",
    "                    found = True\n",
    "                    final.append(compared[cnt])\n",
    "                    compared[cnt] = \"empty\"\n",
    "            cnt = cnt + 1\n",
    "\n",
    " \n",
    "    This script is for printing and readability. Remove once you want to start storing the data some other way\n",
    "    \n",
    "    print(\"Number: \" + str(principal[0]))\n",
    "    print(\"Message: \" + str(principal[1]))\n",
    "    print(\"\")\n",
    "    print(len(final))\n",
    "    print(len(finalVals))\n",
    "    At this point you have finalVals and final in lists final has the sentences and finalVals has the scores and figure out how you\n",
    "    you want to store the data\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range (11):\n",
    "        None\n",
    "\n",
    "        add final[i] to the place to store\n",
    "        add finalVals[i] to the place to store\n",
    "\n",
    "def main():\n",
    "    print(\"start\")\n",
    "    principal = []\n",
    "    data = []\n",
    "    # open both files and add rows to the lists above. Compared will be used later\n",
    "    t0 = time.perf_counter()\n",
    "    with open('data_filtered20.csv', encoding=\"utf8\") as csv:\n",
    "        csv_reader = reader(csv)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    print(\"data finished\")\n",
    "    with open('principal_filtered20.csv', encoding=\"utf8\") as csv:\n",
    "        csv_reader = reader(csv)\n",
    "        for row in csv_reader:\n",
    "            principal.append(row)\n",
    "    print(\"principal finished\")\n",
    "    for index, row in enumerate(principal):\n",
    "        if index is not 0:\n",
    "            t2 = time.perf_counter()\n",
    "            doOperation(data,row)\n",
    "            print(str(index) + \" finished in \" + str(t2- t0) + \" seconds\")\n",
    "    t1 = time.perf_counter()\n",
    "    print(str(t1 - t0))  \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('data_filtered20.csv') \n",
    "df_principal = pd.read_csv('principal_filtered20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_support_sentences(x):\n",
    "    query = [x['sentence']]\n",
    "    element_name = x['element_name']\n",
    "    reg_name = x['reg_name']\n",
    "    corpus = df_data.loc[(df_data['element_name']==element_name) & (df_data['reg_name']==reg_name)]\n",
    "    if corpus.shape[0] >= 20:\n",
    "        return get_similar(query, corpus)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard(str1, str2): \n",
    "    list1 = str1.split(\" \")\n",
    "    list2 = str2.split(\" \")\n",
    "    #tokens_v2_1 = [word for word in list1 if not word in stopwords.words()]\n",
    "    #tokens_v2_2 = [word for word in list2 if not word in stopwords.words()]\n",
    "    return float(100 * textdistance.jaccard(list1 , list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(queries, corpus):   \n",
    "    support_dict = {}\n",
    "    closest_n = 20\n",
    "    distances = []\n",
    "    for query in queries:\n",
    "        for sent in corpus['sentence'].tolist():\n",
    "            try:\n",
    "                distances = np.append(distances, get_jaccard(query,sent))\n",
    "            except:\n",
    "                distances = np.append(distances, 0)\n",
    "        results = zip(corpus['Unnamed: 0'].tolist(), distances)\n",
    "        results = sorted(results, key=lambda x: x[1],reverse=True)\n",
    "        for idx, distance in results[1:closest_n]:\n",
    "            support_dict[idx] = distance\n",
    "    return support_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600187435.5295107\n",
      "5743.895683526993\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(start)\n",
    "df_principal.loc[:, ('support')] = df_principal.apply(get_support_sentences, axis=1)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jaccard = df_principal\n",
    "df_jaccard.to_pickle(\"jaccard.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>element_name</th>\n",
       "      <th>element_type</th>\n",
       "      <th>reg_name</th>\n",
       "      <th>reg_type</th>\n",
       "      <th>reg_label</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>We have recently shown that the accumulation o...</td>\n",
       "      <td>NF-kappaB</td>\n",
       "      <td>Protein Family|Protein Complex</td>\n",
       "      <td>ER</td>\n",
       "      <td>Protein</td>\n",
       "      <td>1</td>\n",
       "      <td>{455424: 0.8564616913033709, 314382: 0.8233839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347</td>\n",
       "      <td>This means in turn reduced liberation of the p...</td>\n",
       "      <td>TNF-alpha</td>\n",
       "      <td>Protein</td>\n",
       "      <td>HMGB1</td>\n",
       "      <td>Protein</td>\n",
       "      <td>0</td>\n",
       "      <td>{439846: 0.7776271781156937, 1774137: 0.768871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>A more unspecific mechanism caused by its anti...</td>\n",
       "      <td>cell death</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>apoptosis</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>0</td>\n",
       "      <td>{1251971: 0.8145650464468555, 2929397: 0.80329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356</td>\n",
       "      <td>It is proposed that a vicious circle develops ...</td>\n",
       "      <td>inflammation</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>TNF-alpha</td>\n",
       "      <td>Protein</td>\n",
       "      <td>1</td>\n",
       "      <td>{2842255: 0.8334853837786113, 1626338: 0.80803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368</td>\n",
       "      <td>When ROS production is enhanced because of NAD...</td>\n",
       "      <td>apoptosis</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>ROS</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>1</td>\n",
       "      <td>{1307004: 0.8559755998904782, 212479: 0.845751...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60836</th>\n",
       "      <td>3865632</td>\n",
       "      <td>Our speculation of the over-riding association...</td>\n",
       "      <td>proliferation</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>PD-1</td>\n",
       "      <td>Protein</td>\n",
       "      <td>1</td>\n",
       "      <td>{2683833: 0.7854059753728427, 1180542: 0.76500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60837</th>\n",
       "      <td>3865636</td>\n",
       "      <td>Moreover , tolerance against brain antigens by...</td>\n",
       "      <td>injury</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>CNS</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>1</td>\n",
       "      <td>{793897: 0.7677901419863133, 3096439: 0.758760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60838</th>\n",
       "      <td>3865884</td>\n",
       "      <td>However , once the negative regulation is lost...</td>\n",
       "      <td>proliferation</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>VEGF</td>\n",
       "      <td>Protein</td>\n",
       "      <td>1</td>\n",
       "      <td>{1926520: 0.8393916434021516, 1437321: 0.83553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60839</th>\n",
       "      <td>3865892</td>\n",
       "      <td>AP1 was reported to be an essential component ...</td>\n",
       "      <td>apoptosis</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>light</td>\n",
       "      <td>Protein</td>\n",
       "      <td>1</td>\n",
       "      <td>{2407046: 0.7961081292110734, 1070327: 0.78567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60840</th>\n",
       "      <td>3865976</td>\n",
       "      <td>This temperature dependent ATP release from hu...</td>\n",
       "      <td>transport</td>\n",
       "      <td>Biological Process</td>\n",
       "      <td>ATP</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>0</td>\n",
       "      <td>{2789525: 0.80308504693721, 795276: 0.78720343...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60841 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           sentence  \\\n",
       "0             274  We have recently shown that the accumulation o...   \n",
       "1             347  This means in turn reduced liberation of the p...   \n",
       "2             354  A more unspecific mechanism caused by its anti...   \n",
       "3             356  It is proposed that a vicious circle develops ...   \n",
       "4             368  When ROS production is enhanced because of NAD...   \n",
       "...           ...                                                ...   \n",
       "60836     3865632  Our speculation of the over-riding association...   \n",
       "60837     3865636  Moreover , tolerance against brain antigens by...   \n",
       "60838     3865884  However , once the negative regulation is lost...   \n",
       "60839     3865892  AP1 was reported to be an essential component ...   \n",
       "60840     3865976  This temperature dependent ATP release from hu...   \n",
       "\n",
       "        element_name                    element_type   reg_name  \\\n",
       "0          NF-kappaB  Protein Family|Protein Complex         ER   \n",
       "1          TNF-alpha                         Protein      HMGB1   \n",
       "2         cell death              Biological Process  apoptosis   \n",
       "3       inflammation              Biological Process  TNF-alpha   \n",
       "4          apoptosis              Biological Process        ROS   \n",
       "...              ...                             ...        ...   \n",
       "60836  proliferation              Biological Process       PD-1   \n",
       "60837         injury              Biological Process        CNS   \n",
       "60838  proliferation              Biological Process       VEGF   \n",
       "60839      apoptosis              Biological Process      light   \n",
       "60840      transport              Biological Process        ATP   \n",
       "\n",
       "                 reg_type  reg_label  \\\n",
       "0                 Protein          1   \n",
       "1                 Protein          0   \n",
       "2      Biological Process          0   \n",
       "3                 Protein          1   \n",
       "4                Chemical          1   \n",
       "...                   ...        ...   \n",
       "60836             Protein          1   \n",
       "60837            Chemical          1   \n",
       "60838             Protein          1   \n",
       "60839             Protein          1   \n",
       "60840            Chemical          0   \n",
       "\n",
       "                                                 support  \n",
       "0      {455424: 0.8564616913033709, 314382: 0.8233839...  \n",
       "1      {439846: 0.7776271781156937, 1774137: 0.768871...  \n",
       "2      {1251971: 0.8145650464468555, 2929397: 0.80329...  \n",
       "3      {2842255: 0.8334853837786113, 1626338: 0.80803...  \n",
       "4      {1307004: 0.8559755998904782, 212479: 0.845751...  \n",
       "...                                                  ...  \n",
       "60836  {2683833: 0.7854059753728427, 1180542: 0.76500...  \n",
       "60837  {793897: 0.7677901419863133, 3096439: 0.758760...  \n",
       "60838  {1926520: 0.8393916434021516, 1437321: 0.83553...  \n",
       "60839  {2407046: 0.7961081292110734, 1070327: 0.78567...  \n",
       "60840  {2789525: 0.80308504693721, 795276: 0.78720343...  \n",
       "\n",
       "[60841 rows x 8 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert = pd.read_pickle(\"support_filtered.pkl\")\n",
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a proportion to see overlap of bert and jaccard 5,10, and 20\n",
    "# Attention analysis on the network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
